{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "#FACE DETECTION PROJECT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flEcmB7AWVi0"
      },
      "outputs": [],
      "source": [
        "#dataset http://chenlab.ece.cornell.edu/people/Andy/ImagesOfGroups.html\n",
        "#https://faceonlive.com/face-detection-models-the-ultimate-guide-2023-unleash-the-power-of-ai-to-spot-faces-like-a-pro/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKsMnqe3SqAl"
      },
      "source": [
        "Haar Cascade Face Detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9SI-aUwS28f",
        "outputId": "e1c0733a-5a38-420f-c3b8-dae1aabb5c92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total images: 430\n",
            "Total faces detected using Haar Cascade face detector: 1220\n",
            "Accuracy: 99.53488372093024\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "\n",
        "dataset_dir = \"/content/drive/MyDrive/Vision_models/Fam2a\"\n",
        "result_dir = \"/content/drive/MyDrive/Vision_models/Results_OpenCV_HaarCascade\"\n",
        "\n",
        "\n",
        "total_images = 0\n",
        "correct_detections = 0\n",
        "total_faces_detected = 0\n",
        "\n",
        "for filename in os.listdir(dataset_dir):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        total_images += 1\n",
        "\n",
        "        image_path = os.path.join(dataset_dir, filename)\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "\n",
        "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "        faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "\n",
        "        total_faces_detected += len(faces)\n",
        "\n",
        "\n",
        "        for (x, y, w, h) in faces:\n",
        "\n",
        "            cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "\n",
        "\n",
        "        result_image_path = os.path.join(result_dir, \"result_\" + filename)\n",
        "        cv2.imwrite(result_image_path, image)\n",
        "\n",
        "\n",
        "        if len(faces) > 0:\n",
        "            correct_detections += 1\n",
        "\n",
        "\n",
        "accuracy = correct_detections / total_images * 100\n",
        "\n",
        "print(\"Total images:\", total_images)\n",
        "print(\"Total faces detected using Haar Cascade face detector:\", total_faces_detected)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nVoCEH0Legl"
      },
      "source": [
        "Model Mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyBR3ZhdRS5f",
        "outputId": "e879f872-b163-46e1-8e10-08997bf74367"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.5.26)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.23)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.23+cuda12.cudnn89)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mediapipe) (2.1.0+cu121)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.8.0.76)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.20.3)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->mediapipe) (2.1.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->mediapipe) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->mediapipe) (1.3.0)\n",
            "Installing collected packages: sounddevice, mediapipe\n",
            "Successfully installed mediapipe-0.10.11 sounddevice-0.4.6\n"
          ]
        }
      ],
      "source": [
        "pip install mediapipe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DomFSM5hLbF4",
        "outputId": "7d5fa5d8-1f47-411c-ad31-df8515340677"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total images: 430\n",
            "Total faces detected using Mediapipe: 784\n",
            "Accuracy: 84.18604651162791\n"
          ]
        }
      ],
      "source": [
        "import mediapipe as mp\n",
        "\n",
        "\n",
        "mp_face_detection = mp.solutions.face_detection\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)\n",
        "\n",
        "\n",
        "dataset_dir = \"/content/drive/MyDrive/Vision_models/Fam2a\"\n",
        "result_dir = \"/content/drive/MyDrive/Vision_models/Results_Mediapipe\"\n",
        "\n",
        "total_images = 0\n",
        "correct_detections = 0\n",
        "total_faces_detected = 0\n",
        "\n",
        "\n",
        "for filename in os.listdir(dataset_dir):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        total_images += 1\n",
        "\n",
        "        image_path = os.path.join(dataset_dir, filename)\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "\n",
        "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "        results = face_detection.process(image_rgb)\n",
        "\n",
        "\n",
        "        if results.detections:\n",
        "            total_faces_detected += len(results.detections)\n",
        "\n",
        "\n",
        "        if results.detections:\n",
        "            for detection in results.detections:\n",
        "                bboxC = detection.location_data.relative_bounding_box\n",
        "                ih, iw, _ = image.shape\n",
        "                x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
        "                cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "\n",
        "\n",
        "        result_image_path = os.path.join(result_dir, \"result_\" + filename)\n",
        "        cv2.imwrite(result_image_path, image)\n",
        "\n",
        "\n",
        "        if results.detections:\n",
        "            correct_detections += 1\n",
        "\n",
        "\n",
        "accuracy = correct_detections / total_images * 100\n",
        "\n",
        "print(\"Total images:\", total_images)\n",
        "print(\"Total faces detected using Mediapipe:\", total_faces_detected)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7MynWcaI1Dq"
      },
      "source": [
        "CNN with dlib library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phBYAGPID6Dy",
        "outputId": "87e9d7e0-cecb-4c8d-9d2e-1bcf2399d0e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dlib in /usr/local/lib/python3.10/dist-packages (19.24.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install dlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nfmo8BdfOq2h",
        "outputId": "ec9d80a3-ef1e-47bf-9f22-bcfb4edc0ca9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total images: 430\n",
            "Total faces detected: 1106\n",
            "Accuracy: 99.06976744186046\n"
          ]
        }
      ],
      "source": [
        "import dlib\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "cnn_face_detector = dlib.cnn_face_detection_model_v1(\"/content/drive/MyDrive/Vision_models/mmod_human_face_detector.dat\")\n",
        "\n",
        "\n",
        "dataset_dir = \"/content/drive/MyDrive/Vision_models/Fam2a\"\n",
        "result_dir = \"/content/drive/MyDrive/Vision_models/Results\"\n",
        "\n",
        "\n",
        "total_images = 0\n",
        "correct_detections = 0\n",
        "total_faces_detected = 0\n",
        "\n",
        "\n",
        "for filename in os.listdir(dataset_dir):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        total_images += 1\n",
        "\n",
        "        image_path = os.path.join(dataset_dir, filename)\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "\n",
        "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "        faces = cnn_face_detector(gray_image, 1)\n",
        "\n",
        "\n",
        "        total_faces_detected += len(faces)\n",
        "\n",
        "\n",
        "        for face in faces:\n",
        "            x, y, w, h = (face.rect.left(), face.rect.top(), face.rect.width(), face.rect.height())\n",
        "\n",
        "\n",
        "            cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "\n",
        "\n",
        "        result_image_path = os.path.join(result_dir, \"result_\" + filename)\n",
        "        cv2.imwrite(result_image_path, image)\n",
        "\n",
        "\n",
        "        if len(faces) > 0:\n",
        "            correct_detections += 1\n",
        "\n",
        "\n",
        "accuracy = correct_detections / total_images * 100\n",
        "\n",
        "print(\"Total images:\", total_images)\n",
        "print(\"Total faces detected:\", total_faces_detected)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
